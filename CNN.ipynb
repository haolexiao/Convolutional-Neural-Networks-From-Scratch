{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000, 10)\n",
      "Validation set (10000, 28, 28) (10000, 10)\n",
      "Test set (10000, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(inX):  \n",
    "    return 1.0/(1.0+np.exp(-inX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def max_pooling(data,pooling):\n",
    "    output = np.zeros([data.shape[0]/pooling[0],data.shape[1]/pooling[1]])\n",
    "    for i in range(output.shape[0]):\n",
    "        for j in range(output.shape[1]):\n",
    "            output[i,j] = data[i*pooling[0]:(i+1)*pooling[0],j*pooling[1]:(j+1)*pooling[1]].mean()\n",
    "    return output\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x-x.max(0)) / np.sum(np.exp(x-x.max(0)), axis=0)\n",
    "\n",
    "def rot180(conv_kernel):\n",
    "    return np.fliplr( np.flipud(conv_kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class layer(object):\n",
    "    w = []\n",
    "    b = []\n",
    "    type = ''\n",
    "    input_nums = 0\n",
    "    output_nums = 0\n",
    "    kernel_size = 0\n",
    "    mapsize = []\n",
    "    a = []\n",
    "    d = []\n",
    "    dw = []\n",
    "    db = []\n",
    "    #mapsize means input size, it's a 2 nums vector\n",
    "    #input_nums means what's the numbers of feature/channels\n",
    "    #out_nums means whate's the numbers of output feature \n",
    "    #kernel_size means if it is convertional layer, its kernel size\n",
    "    #type_size means the layer's type: 's' means pooling layer, 'c' means convertional layer, 'f' means full-connected layer\n",
    "    def __init__(self,_mapsize,in_n,out_n,k_size,type_str):\n",
    "        self.mapsize = _mapsize\n",
    "        self.input_nums = in_n\n",
    "        self.output_nums = out_n\n",
    "        self.kernel_size = k_size\n",
    "        self.type = type_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class options(object):\n",
    "    alpha = 0.1\n",
    "    epochs = 5\n",
    "    batch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class cnn(object):\n",
    "    cnn_layer = []\n",
    "    output_d = []\n",
    "    def __init__(self,x, kernel_size,y_size):\n",
    "        input_size = x[0].shape\n",
    "        mapsize = [input_size[0]-kernel_size+1,input_size[1]-kernel_size+1]\n",
    "        self.cnn_layer.append(layer(mapsize,1,6,kernel_size,'c'))\n",
    "        \n",
    "        mapsize = [mapsize[0]/2,mapsize[1]/2]\n",
    "        self.cnn_layer.append(layer(mapsize,6,6,2,'s'))\n",
    "        \n",
    "        mapsize = [mapsize[0]-5+1,mapsize[1]-5+1]\n",
    "        self.cnn_layer.append(layer(mapsize,6,12,5,'c'))\n",
    "        \n",
    "        mapsize = [mapsize[0]/2,mapsize[1]/2]\n",
    "        self.cnn_layer.append(layer(mapsize,12,12,2,'s'))\n",
    "        \n",
    "        mapsize = mapsize[0]*mapsize[1]*12\n",
    "        self.cnn_layer.append(layer(mapsize,12,y_size,1,'f'))\n",
    "    \n",
    "    def init_w(self):\n",
    "        self.cnn_layer[0].w = np.random.randn(self.cnn_layer[0].input_nums,self.cnn_layer[0].output_nums,self.cnn_layer[0].kernel_size,self.cnn_layer[0].kernel_size)\n",
    "        self.cnn_layer[1].w = np.ones([self.cnn_layer[1].kernel_size,self.cnn_layer[1].kernel_size])/4\n",
    "        self.cnn_layer[2].w = np.random.randn(self.cnn_layer[2].input_nums,self.cnn_layer[2].output_nums,self.cnn_layer[2].kernel_size,self.cnn_layer[2].kernel_size)\n",
    "        self.cnn_layer[3].w = np.ones([self.cnn_layer[3].kernel_size,self.cnn_layer[1].kernel_size])/4\n",
    "        self.cnn_layer[4].w = np.random.randn(self.cnn_layer[4].mapsize,self.cnn_layer[4].output_nums)\n",
    "        \n",
    "        self.cnn_layer[0].b = np.zeros(self.cnn_layer[0].output_nums)\n",
    "        self.cnn_layer[1].b = 0\n",
    "        self.cnn_layer[2].b = np.zeros(self.cnn_layer[2].output_nums)\n",
    "        self.cnn_layer[3].b = 0\n",
    "        self.cnn_layer[4].b = np.zeros([1,self.cnn_layer[4].output_nums])\n",
    "    \n",
    "    def cnnff(self,x):\n",
    "        nums = x.shape[0]\n",
    "        #compute 1st layer-Convolutional layer\n",
    "        in_n = self.cnn_layer[0].input_nums\n",
    "        out_n = self.cnn_layer[0].output_nums\n",
    "        self.cnn_layer[0].a = np.zeros([nums,out_n]+self.cnn_layer[0].mapsize)\n",
    "        for k in xrange(nums):\n",
    "            for i in xrange(out_n):\n",
    "                z = np.zeros(self.cnn_layer[0].mapsize)\n",
    "                for j in xrange(in_n):\n",
    "                    z += scipy.signal.convolve2d(x[k],self.cnn_layer[0].w[j,i],'valid')\n",
    "                self.cnn_layer[0].a[k][i] = sigmoid(z+self.cnn_layer[0].b[i])\n",
    "\n",
    "                   \n",
    "        #compute 2nd layer-Pooling layer\n",
    "        out_n = self.cnn_layer[0].output_nums\n",
    "        self.cnn_layer[1].a = np.zeros([nums,out_n]+self.cnn_layer[1].mapsize)\n",
    "        for k in xrange(nums):\n",
    "            for i in xrange(out_n):\n",
    "                self.cnn_layer[1].a[k][i] = max_pooling(self.cnn_layer[0].a[k][i],[2,2])\n",
    "        \n",
    "\n",
    "        #compute 3nd layer-Convolutional layer\n",
    "        in_n = self.cnn_layer[2].input_nums\n",
    "        out_n = self.cnn_layer[2].output_nums\n",
    "        self.cnn_layer[2].a = np.zeros([nums,out_n]+self.cnn_layer[2].mapsize)\n",
    "        for k in xrange(nums):\n",
    "            for i in xrange(out_n):\n",
    "                z = np.zeros(self.cnn_layer[2].mapsize)\n",
    "                for j in xrange(in_n):\n",
    "                    z += scipy.signal.convolve2d(self.cnn_layer[1].a[k][j],self.cnn_layer[2].w[j,i],'valid')\n",
    "                self.cnn_layer[2].a[k][i] = sigmoid(z+self.cnn_layer[2].b[i])\n",
    "        \n",
    "        \n",
    "        #compute 4th layer-Pooling layer\n",
    "        out_n = self.cnn_layer[3].output_nums\n",
    "        self.cnn_layer[3].a = np.zeros([nums,out_n]+self.cnn_layer[3].mapsize)\n",
    "        for k in xrange(nums):\n",
    "            for i in xrange(out_n):\n",
    "                self.cnn_layer[3].a[k][i] = max_pooling(self.cnn_layer[2].a[k][i],[2,2])\n",
    "        \n",
    "\n",
    "        #compute 5nd layer-softmax output layer\n",
    "        feature_vector = np.array(self.cnn_layer[3].a).reshape(nums,192)\n",
    "        raw_output = np.dot(feature_vector,self.cnn_layer[4].w)+np.matlib.repmat(self.cnn_layer[4].b,nums,1)\n",
    "        self.cnn_layer[4].a = softmax(raw_output.T).T\n",
    "        #print(self.cnn_layer[0].a[0][0][0])\n",
    "        \n",
    "    def compute_error(self,y):\n",
    "        tmp = np.log(self.cnn_layer[4].a)*y\n",
    "        \n",
    "        return (-tmp.sum()/y.shape[0],(np.argmax(y,1) == np.argmax(self.cnn_layer[4].a,1) ).astype(np.float32).sum()/y.shape[0])\n",
    "    \n",
    "    def cnnbp(self,x,y):\n",
    "        nums = y.shape[0]\n",
    "        #compute 5st layer-error\n",
    "        #self.cnn_layer[4].d is a k*10 matrix\n",
    "        self.cnn_layer[4].d = (self.cnn_layer[4].a-y)\n",
    "        \n",
    "        \n",
    "        #compute 4th layer-error\n",
    "        #tmp_d is a k*192 matrix\n",
    "        tmp_d = np.dot(self.cnn_layer[4].d,self.cnn_layer[4].w.T)\n",
    "        out_n = self.cnn_layer[3].output_nums\n",
    "        tmp_size = self.cnn_layer[3].mapsize\n",
    "        #self.cnn_layer[4].d is a k*12*4*4 matrix\n",
    "        self.cnn_layer[3].d = np.zeros([nums,out_n]+self.cnn_layer[3].mapsize)\n",
    "        \n",
    "        for k in xrange(nums):\n",
    "            for i in xrange(out_n):\n",
    "                self.cnn_layer[3].d[k][i] = (tmp_d[k][i*tmp_size[0]*tmp_size[1]:(i+1)*tmp_size[0]*tmp_size[1]]).reshape(tmp_size[0],tmp_size[1])\n",
    "        #print(out_n,self.cnn_layer[3].d[0][0].shape)\n",
    "        \n",
    "        #compute 3rd layer-error\n",
    "        #self.cnn_layer[3]\n",
    "        self.cnn_layer[2].d = np.zeros([nums,out_n]+self.cnn_layer[2].mapsize)\n",
    "        for k in xrange(nums):\n",
    "            for t in xrange(out_n):\n",
    "                for i in xrange(tmp_size[0]):\n",
    "                    for j in xrange(tmp_size[1]):\n",
    "                        self.cnn_layer[2].d[k][t][i,j] = self.cnn_layer[3].d[k][t][i/2,j/2]\n",
    "                self.cnn_layer[2].d[k][t] = self.cnn_layer[2].d[k][t]/4 * (1-self.cnn_layer[2].a[k][t])*self.cnn_layer[2].a[k][t]\n",
    "        #print(out_n,self.cnn_layer[2].d[0][0].shape)\n",
    "        \n",
    "        #compute 2rd layer-error\n",
    "        out_n = self.cnn_layer[2].output_nums\n",
    "        in_n = self.cnn_layer[2].input_nums\n",
    "        self.cnn_layer[1].d = np.zeros([nums,in_n]+self.cnn_layer[1].mapsize)\n",
    "        for k in xrange(nums):\n",
    "            for i in xrange(in_n):\n",
    "                z = np.zeros(self.cnn_layer[1].mapsize)\n",
    "                for j in xrange(out_n):\n",
    "                    z += scipy.signal.convolve2d(self.cnn_layer[2].d[k][j],rot180(self.cnn_layer[2].w[i][j]),'full')\n",
    "                self.cnn_layer[1].d[k][i] = z;\n",
    "        #print(in_n,self.cnn_layer[1].d[0][0].shape)\n",
    "        \n",
    "        #compute 1st layer-error\n",
    "        #self.cnn_layer[0]\n",
    "        tmp_size = self.cnn_layer[0].mapsize\n",
    "        self.cnn_layer[0].d = np.zeros([nums,in_n]+tmp_size)\n",
    "        for k in xrange(nums):\n",
    "            for t in xrange(in_n):\n",
    "                for i in xrange(tmp_size[0]):\n",
    "                    for j in xrange(tmp_size[1]):\n",
    "                        self.cnn_layer[0].d[k][t][i,j] = self.cnn_layer[1].d[k][t][i/2,j/2]\n",
    "                self.cnn_layer[0].d[k][t] = self.cnn_layer[0].d[k][t]/4 * (1-self.cnn_layer[0].a[k][t])*self.cnn_layer[0].a[k][t]\n",
    "        #print(in_n,self.cnn_layer[0].d[0][0].shape)\n",
    "        \n",
    "        \n",
    "        #compute grantiant of w and b:\n",
    "        #compute 1st layer-conventional layer\n",
    "        out_n = self.cnn_layer[0].output_nums\n",
    "        in_n = self.cnn_layer[0].input_nums\n",
    "        tmp_size = self.cnn_layer[0].mapsize\n",
    "        self.cnn_layer[0].dw = np.zeros([in_n,out_n,self.cnn_layer[0].kernel_size,self.cnn_layer[0].kernel_size])\n",
    "        self.cnn_layer[0].db = [0]*out_n\n",
    "        for j in xrange(out_n):\n",
    "            for i in xrange(in_n):\n",
    "                for k in xrange(nums):\n",
    "                    self.cnn_layer[0].dw[i][j] += scipy.signal.convolve2d(rot180(x[k]),self.cnn_layer[0].d[k][j],'valid')\n",
    "                self.cnn_layer[0].dw[i][j] = self.cnn_layer[0].dw[i][j]/nums;\n",
    "            for k in xrange(nums):\n",
    "                self.cnn_layer[0].db[j] += self.cnn_layer[0].d[k][j].sum()\n",
    "            self.cnn_layer[0].db[j] = self.cnn_layer[0].db[j]/nums;\n",
    "        \n",
    "        #compute 3nd layer-conventional layer\n",
    "        out_n = self.cnn_layer[2].output_nums\n",
    "        in_n = self.cnn_layer[2].input_nums\n",
    "        tmp_size = self.cnn_layer[0].mapsize\n",
    "        self.cnn_layer[2].dw = np.zeros([in_n,out_n,self.cnn_layer[2].kernel_size,self.cnn_layer[2].kernel_size])\n",
    "        self.cnn_layer[2].db = [0]*out_n\n",
    "        for j in xrange(out_n):\n",
    "            for i in xrange(in_n):\n",
    "                for k in xrange(nums):\n",
    "                    self.cnn_layer[2].dw[i][j] += scipy.signal.convolve2d(rot180(self.cnn_layer[1].a[k][i]),self.cnn_layer[2].d[k][j],'valid')\n",
    "                self.cnn_layer[2].dw[i][j] = self.cnn_layer[2].dw[i][j]/nums;\n",
    "            for k in xrange(nums):\n",
    "                self.cnn_layer[2].db[j] += self.cnn_layer[2].d[k][j].sum()\n",
    "            self.cnn_layer[2].db[j] = self.cnn_layer[2].db[j]/nums;\n",
    "        \n",
    "        #compute the output layer:\n",
    "        feature_vector = np.array(self.cnn_layer[3].a).reshape(nums,192)\n",
    "        self.cnn_layer[4].dw = np.dot(feature_vector.T,self.cnn_layer[4].d)/nums\n",
    "        self.cnn_layer[4].db = self.cnn_layer[4].d.mean(0)\n",
    "    \n",
    "    def cnnapplygrads(self,options):\n",
    "        #applygrads in 1st layer:\n",
    "        out_n = self.cnn_layer[0].output_nums\n",
    "        in_n = self.cnn_layer[0].input_nums\n",
    "        for j in xrange(out_n):\n",
    "            for i in xrange(in_n):\n",
    "                self.cnn_layer[0].w[i][j] = self.cnn_layer[0].w[i][j] - options.alpha*self.cnn_layer[0].dw[i][j]\n",
    "            self.cnn_layer[0].b[j] = self.cnn_layer[0].b[j] - options.alpha*self.cnn_layer[0].db[j]\n",
    "        \n",
    "        #applygrads in 3nd layer:\n",
    "        out_n = self.cnn_layer[2].output_nums\n",
    "        in_n = self.cnn_layer[2].input_nums\n",
    "        for j in xrange(out_n):\n",
    "            for i in xrange(in_n):\n",
    "                self.cnn_layer[2].w[i][j] = self.cnn_layer[2].w[i][j] - options.alpha*self.cnn_layer[2].dw[i][j]\n",
    "            self.cnn_layer[2].b[j] = self.cnn_layer[2].b[j] - options.alpha*self.cnn_layer[2].db[j]\n",
    "            \n",
    "        #applygrads in output layer:\n",
    "        self.cnn_layer[4].w = self.cnn_layer[4].w - options.alpha*self.cnn_layer[4].dw\n",
    "        self.cnn_layer[4].b = self.cnn_layer[4].b - options.alpha*self.cnn_layer[4].db\n",
    "        \n",
    "    def train(self,train_dataset,train_labels,options):\n",
    "        nums = train_dataset.shape[0]\n",
    "        for i in xrange(options.epochs):\n",
    "            for j in xrange(nums/options.batch):\n",
    "                x_tmp = train_dataset[j*options.batch:(j+1)*options.batch]\n",
    "                y_tmp = train_labels[j*options.batch:(j+1)*options.batch]\n",
    "                self.cnnff(x_tmp)\n",
    "                print(tmp.compute_error(y_tmp))\n",
    "                self.cnnbp(x_tmp,y_tmp)\n",
    "                self.cnnapplygrads(opt)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = cnn(x_tmp,5,10)\n",
    "tmp.init_w()\n",
    "opt = option()\n",
    "tmp.train(train_dataset,train_labels,opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
